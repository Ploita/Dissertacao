{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59224/3818098783.py:260: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout(rect=[0, 0, 0.9, 1]) # Ajusta o layout para dar espaço à colorbar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot de Recompensa concluído.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "plt.style.use('style.mplstyle')\n",
    "\n",
    "def fechar_plot(directory, filename, xlabel='Época/Iteração', ylabel='Valor'):\n",
    "    \"\"\"Salva o gráfico atual e o fecha, garantindo o tight layout.\"\"\"\n",
    "    plots_dir = os.path.join(directory, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Define o sufixo do título apenas para métricas que usam Média e STD\n",
    "    title_suffix = ' (Média ± STD)' if any(s in filename for s in ['loss', 'grad', 'weight']) else ''\n",
    "    plt.title(f'{filename.replace(\"_\", \" \").title()}{title_suffix}')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    if plt.gca().get_lines() or plt.gca().collections:\n",
    "         plt.legend() \n",
    "    \n",
    "    try:\n",
    "        plt.tight_layout()\n",
    "    except Exception:\n",
    "        pass \n",
    "        \n",
    "    plt.savefig(os.path.join(plots_dir, f'{filename}.pdf'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def coletar_dados_experimentos(caminho_base):\n",
    "    \"\"\"\n",
    "    Varre as subpastas, lê 'resultados.csv', concatena e salva o arquivo compilado.\n",
    "    Retorna o DataFrame compilado.\n",
    "    \"\"\"\n",
    "    dados_totais = []\n",
    "    \n",
    "    try:\n",
    "        conteudo_pasta = os.listdir(caminho_base)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: O caminho base '{caminho_base}' não foi encontrado.\")\n",
    "        return None    \n",
    "    \n",
    "    for nome_pasta in conteudo_pasta:\n",
    "        caminho_experimento = os.path.join(caminho_base, nome_pasta)\n",
    "\n",
    "        if os.path.isdir(caminho_experimento):\n",
    "            caminho_csv = os.path.join(caminho_experimento, 'resultados.csv')\n",
    "            if os.path.exists(caminho_csv):\n",
    "                try:\n",
    "                    df = pd.read_csv(caminho_csv)\n",
    "                    df['id_experimento'] = nome_pasta\n",
    "                    dados_totais.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao ler o arquivo {caminho_csv}: {e}\")\n",
    "            else:\n",
    "                pass \n",
    "\n",
    "    if not dados_totais:\n",
    "        print(\"Nenhum dado de experimento ('resultados.csv') foi encontrado nas subpastas.\")\n",
    "        return None\n",
    "\n",
    "    df_final = pd.concat(dados_totais, ignore_index=True)\n",
    "    \n",
    "    # Cria o nome do arquivo de saída usando o nome do ambiente\n",
    "    match = re.search(r'groups/([^/]+)', caminho_base)\n",
    "    ambiente_nome = match.group(1) if match else 'unknown_environment'\n",
    "    \n",
    "    caminho_saida = os.path.join(caminho_base, 'plots', f\"compilado_{ambiente_nome}.csv\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(caminho_saida), exist_ok=True)\n",
    "    df_final.to_csv(path_or_buf=caminho_saida, mode='w', index=False)\n",
    "    return df_final, caminho_saida\n",
    "\n",
    "def load_and_group_data(df):\n",
    "    \"\"\"\n",
    "    Recebe o DataFrame compilado, calcula o 'timestep' por experimento, \n",
    "    e então calcula Média e Desvio Padrão para TODAS as métricas.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "\n",
    "    if 'id_experimento' not in df.columns:\n",
    "        print(f\"Erro: Coluna 'id_experimento' não encontrada no DataFrame compilado.\")\n",
    "        return None\n",
    "\n",
    "    # Garante que 'id_experimento' não seja agrupada\n",
    "    group_by_cols = [col for col in df.columns if col != 'id_experimento']\n",
    "    \n",
    "    # Cria a coluna 'timestep' (época/iteração) para cada experimento\n",
    "    df['timestep'] = df.groupby('id_experimento').cumcount()\n",
    "    \n",
    "    # Agrupa por 'timestep' e calcula a Média e o STD de todas as métricas\n",
    "    grouped_data = df.groupby('timestep')[group_by_cols].agg(['mean', 'std'])\n",
    "    \n",
    "    # Renomeia as colunas para o formato 'métrica_agregação'\n",
    "    grouped_data.columns = [f'{col[0]}_{col[1]}' for col in grouped_data.columns]\n",
    "    \n",
    "    return grouped_data.reset_index()\n",
    "\n",
    "def load_rewards_from_folders(root_directory, folder_list, rewards_filename='rewards.csv'):\n",
    "    \"\"\"\n",
    "    Lê os rewards.csv, transforma (transpõe) e calcula a Média e STD por timestep.\n",
    "    \"\"\"\n",
    "    all_experiments_df = []\n",
    "    \n",
    "    for folder_name in folder_list:\n",
    "        file_path = os.path.join(root_directory, folder_name, rewards_filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "        try:\n",
    "            # Lê, transpõe e garante que os dados são numéricos\n",
    "            df_reward = pd.read_csv(file_path, header=0).T\n",
    "            df_reward = df_reward.apply(pd.to_numeric, errors='coerce')\n",
    "            df_reward['experiment_id'] = folder_name\n",
    "            all_experiments_df.append(df_reward)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {file_path}: {e}\")\n",
    "            \n",
    "    if not all_experiments_df:\n",
    "        return None\n",
    "\n",
    "    combined_df = pd.concat(all_experiments_df, ignore_index=True)\n",
    "    data_cols = combined_df.drop(columns=['experiment_id']).dropna(axis=1, how='all')\n",
    "    \n",
    "    mean_rewards = data_cols.mean(axis=0)\n",
    "    std_rewards = data_cols.std(axis=0)\n",
    "    \n",
    "    grouped_data = pd.DataFrame({\n",
    "        'timestep': mean_rewards.index, \n",
    "        'mean_reward': mean_rewards.values,\n",
    "        'std_reward': std_rewards.values\n",
    "    })\n",
    "    \n",
    "    grouped_data['timestep'] = pd.to_numeric(grouped_data['timestep'], errors='coerce')\n",
    "\n",
    "    return grouped_data\n",
    "\n",
    "def plot_reward_mean_std(grouped_data, directory):\n",
    "    \"\"\"Gera o plot de Recompensa (Média +/- std).\"\"\"\n",
    "    if grouped_data is None or grouped_data.empty:\n",
    "        print(\"Aviso: Dados de recompensa agrupados estão vazios. Pulando plotagem de Recompensa.\")\n",
    "        return\n",
    "        \n",
    "    plt.figure()\n",
    "    mean = grouped_data['mean_reward']\n",
    "    std = grouped_data['std_reward']\n",
    "    timestep = grouped_data['timestep']\n",
    "    \n",
    "    plt.plot(timestep, mean, label='Média de Recompensa', color='blue')\n",
    "    \n",
    "    plt.fill_between(\n",
    "        timestep,\n",
    "        mean - std, \n",
    "        mean + std,   \n",
    "        alpha=0.2,                     \n",
    "        color='blue',\n",
    "    )\n",
    "\n",
    "    fechar_plot(directory, 'reward_mean_std', 'Iteração/Época', 'Recompensa Média')\n",
    "\n",
    "def plot_rl_metrics(data_grouped, directory):\n",
    "    \"\"\"\n",
    "    Gera plots de Loss (com componentes), Gradiente e Pesos (média +/- std).\n",
    "    \"\"\"\n",
    "    if data_grouped is None or data_grouped.empty:\n",
    "        return\n",
    "        \n",
    "    metric_map = OrderedDict([\n",
    "        ('loss', {'title': 'Componentes da Loss', 'ylabel': 'Valor da Loss Média', 'components': ['entropy_loss', 'policy_gradient_loss', 'value_loss']}),\n",
    "        ('actor_weight', {'title': 'Pesos do Ator', 'ylabel': 'Valor do Peso', 'components': None}),\n",
    "        ('actor_grad', {'title': 'Gradiente do Ator', 'ylabel': 'Valor do Gradiente', 'components': None}),\n",
    "        ('critic_weight', {'title': 'Pesos do Crítico', 'ylabel': 'Valor do Peso', 'components': None}),\n",
    "        ('critic_grad', {'title': 'Gradiente do Crítico', 'ylabel': 'Valor do Gradiente', 'components': None}),\n",
    "    ])\n",
    "\n",
    "    for metric_prefix, info in metric_map.items():\n",
    "        plt.figure()\n",
    "        \n",
    "        if info['components']:\n",
    "            plot_list = info['components']\n",
    "        else:\n",
    "            # Encontra todas as colunas que começam com o prefixo e terminam com _mean\n",
    "            all_means = [col.replace('_mean', '') for col in data_grouped.columns if col.startswith(metric_prefix) and col.endswith('_mean')]\n",
    "            if not all_means:\n",
    "                continue\n",
    "            plot_list = all_means\n",
    "\n",
    "        for prefix in plot_list:\n",
    "            mean_col = f'{prefix}_mean'\n",
    "            std_col = f'{prefix}_std'\n",
    "            if mean_col not in data_grouped.columns:\n",
    "                continue\n",
    "\n",
    "            legend_name = prefix.replace('_', ' ').title()\n",
    "            plt.plot(data_grouped['timestep'], data_grouped[mean_col], label=legend_name)\n",
    "            \n",
    "            if std_col in data_grouped.columns:\n",
    "                plt.fill_between(\n",
    "                    data_grouped['timestep'],\n",
    "                    data_grouped[mean_col] - data_grouped[std_col],\n",
    "                    data_grouped[mean_col] + data_grouped[std_col],\n",
    "                    alpha=0.2,\n",
    "                )\n",
    "\n",
    "        fechar_plot(directory, metric_prefix, 'Época', info['ylabel'])\n",
    "\n",
    "def plot_im_subplots(data, name, output_dir):\n",
    "    \"\"\"\n",
    "    Plots todas as combinações de Informação Mútua (IM) em subplots de dispersão.\n",
    "    \"\"\"\n",
    "    if data is None or data.empty: \n",
    "        print(\"Aviso: Dados agrupados para IM estão vazios. Pulando plotagem de IM.\")\n",
    "        return\n",
    "    \n",
    "    im_combinations = [\n",
    "        ('I(X,h_1)', 'I(h_1,h_2)', 'Relação $I(X,h_1) \\\\times I(h_1,h_2)$'),\n",
    "        ('I(X,h_1)', 'I(h_1,hat Y)', 'Relação $I(X,h_1) \\\\times I(h_1,\\\\hat Y)$'),\n",
    "        ('I(X,h_2)', 'I(h_2,hat Y)', 'Relação $I(X,h_2) \\\\times I(h_2,\\\\hat Y)$'),\n",
    "        ('I(h_1,h_2)', 'I(h_2,hat Y)', 'Relação $I(h_1,h_h2) \\\\times I(h_2,\\\\hat Y)$')\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "    axes = axes.flatten() \n",
    "    lista_letra = ['a)', 'b)', 'c)', 'd)']\n",
    "\n",
    "    for i, (col_x, col_y, title) in enumerate(im_combinations):\n",
    "        ax = axes[i] \n",
    "        \n",
    "        col_x_mean = f'{col_x}_mean'\n",
    "        col_y_mean = f'{col_y}_mean'\n",
    "\n",
    "        if col_x_mean not in data.columns or col_y_mean not in data.columns:\n",
    "            ax.set_visible(False) \n",
    "            continue\n",
    "        \n",
    "        val_x_mean = data[col_x_mean]\n",
    "        val_y_mean = data[col_y_mean]\n",
    "        \n",
    "        scatter = ax.scatter(\n",
    "            val_x_mean, \n",
    "            val_y_mean,\n",
    "            c=data['timestep'],\n",
    "            cmap='magma',\n",
    "        )\n",
    "        \n",
    "        # Formatando labels com LaTeX\n",
    "        x_label = col_x.replace('hat', '\\\\hat')\n",
    "        y_label = col_y.replace('hat', '\\\\hat')\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'${x_label}$')\n",
    "        ax.set_ylabel(f'${y_label}$')\n",
    "        ax.text(0.02,0.98,lista_letra[i], transform=ax.transAxes, va='top')\n",
    "        \n",
    "    # Adicionando a Colorbar fora da área principal\n",
    "    cbar_ax = fig.add_axes([0.95, 0.1, 0.025, 0.8]) # Posição ajustada\n",
    "    fig.colorbar(scatter, cax=cbar_ax, label= 'Épocas')\n",
    "    fig.tight_layout(rect=[0, 0, 0.9, 1]) # Ajusta o layout para dar espaço à colorbar\n",
    "\n",
    "    plots_dir = os.path.join(output_dir, 'plots')\n",
    "\n",
    "    match = re.search(r'compilado_(.+)\\.csv', name)\n",
    "    if match:\n",
    "        enviroment = match.group(1)\n",
    "        plt.savefig(os.path.join(plots_dir, f'Mean_IM_{enviroment}.pdf'))\n",
    "    else:\n",
    "        plt.savefig(os.path.join(plots_dir, f'Mean_IM_unknown.pdf'))\n",
    "        \n",
    "    plt.close()\n",
    "\n",
    "def main_pipeline(enviroment_name, root_dir_prefix='../data/groups/'):\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo: coleta, agrupa e plota.\n",
    "    \"\"\"\n",
    "    root_directory = os.path.join(root_dir_prefix, enviroment_name)\n",
    "\n",
    "    try:\n",
    "        df_completo, compiled_data_path = coletar_dados_experimentos(root_directory)\n",
    "    except TypeError:\n",
    "         # Se a função retornar None, o df_completo será None, e o pipeline para aqui.\n",
    "         print(\"Erro na coleta de dados. Terminando o pipeline.\")\n",
    "         return\n",
    "    \n",
    "    if df_completo is None:\n",
    "        return\n",
    "        \n",
    "    output_dir = root_directory\n",
    "    grouped_data_compiled = load_and_group_data(df_completo)\n",
    "    \n",
    "    if grouped_data_compiled is not None:\n",
    "        \n",
    "        # Plotagem de Loss, Gradiente e Pesos\n",
    "        try:\n",
    "            plot_rl_metrics(grouped_data_compiled, output_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao gerar plots de métricas RL: {e}\")\n",
    "            \n",
    "        # Plotagem de Informação Mútua (IM)\n",
    "        try:\n",
    "            plot_im_subplots(grouped_data_compiled, compiled_data_path, output_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao gerar plots de IM: {e}\")\n",
    "            \n",
    "    try:\n",
    "        folder_names = [d for d in os.listdir(root_directory) if os.path.isdir(os.path.join(root_directory, d))]\n",
    "        if folder_names:\n",
    "            grouped_rewards = load_rewards_from_folders(root_directory, folder_names)\n",
    "            if grouped_rewards is not None:\n",
    "                plot_reward_mean_std(grouped_rewards, output_dir)\n",
    "        else:\n",
    "             print(f\"\\nAviso: Nenhuma subpasta de experimento encontrada em {root_directory}. Pulando plotagem de Recompensa.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nAviso: Diretório de recompensas {root_directory} não encontrado. Pulando plotagem de Recompensa.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro ao processar plots de Recompensa: {e}\")\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    environment_to_run = 'Acrobot_2x32' \n",
    "    main_pipeline(environment_to_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertacao (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
