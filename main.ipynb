{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# connect mlflow client to the mlflow server that runs on localhost:5000\n",
    "MLFLOW_SERVER_URI = 'http://localhost:5000'\n",
    "mlflow.set_tracking_uri(str(MLFLOW_SERVER_URI))\n",
    "\n",
    "EXPERIMENT_NAME = 'DQN_24_02_08'\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "from config import OPTUNA_DB\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=EXPERIMENT_NAME,\n",
    "    direction='maximize',\n",
    "    load_if_exists=True,\n",
    "    storage=f'sqlite:///{OPTUNA_DB}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia é treinar cada conjunto de hiperparâmetros por 200 épocas e avaliar por 1000, a função retorna a recompensa média dessas 1000 iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimize_hyperparameters import objective\n",
    "\n",
    "# we define a lambda function because study.optimize()\n",
    "# expect the objective function to have only 1 input\n",
    "# (trial), while our objective function hast 2 extra\n",
    "# inputs I defined to add flexibility to the script\n",
    "func = lambda trial: objective(trial,\n",
    "                               force_linear_model=False,\n",
    "                               n_episodes_to_train=200)\n",
    "\n",
    "class CheckHyperparamMeanRewardThreshold:\n",
    "    def __init__(self, reward_threshold: float):\n",
    "        self.reward_threshold = reward_threshold\n",
    "\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        if trial.value is not None and trial.value >= self.reward_threshold:\n",
    "            print((f'Stopping hyperparameter search because trial.value ({trial.value}) '\n",
    "                   f'hit threshold ({self.reward_threshold})'))\n",
    "            study.stop()\n",
    "\n",
    "# Stop hyperparameter search when we hit a perfect mean reward of 500\n",
    "hyperparam_search_stop_callback = CheckHyperparamMeanRewardThreshold(500.0)\n",
    "\n",
    "study.optimize(func, n_trials=1000, callbacks=[hyperparam_search_stop_callback], show_progress_bar=True)\n",
    "# Existe um puta problema relacionado ao como representar redes com múltiplas camadas, não estou com saco pra resolver isso agora\n",
    "# mas saiba que existe e que pra resolver precisa dissecar o dicionário de parâmetros que o optuna usa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "\n",
    "hparams = {k: best_trial.params[k] for k in best_trial.params if k != 'seed'}\n",
    "#hparams['nn_hidden_layers'] = eval(hparams['nn_hidden_layers']) \n",
    "print(hparams)\n",
    "\n",
    "SEED = best_trial.params['seed']\n",
    "print('Seed: ', SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from q_agent import QAgent\n",
    "from config import SAVED_AGENTS_DIR\n",
    "\n",
    "diretorio_pai = SAVED_AGENTS_DIR / 'CartPole-v1'\n",
    "\n",
    "# Lista de todos os diretórios no diretório_pai\n",
    "diretorios = [d for d in os.listdir(diretorio_pai) if os.path.isdir(os.path.join(diretorio_pai, d))]\n",
    "\n",
    "# Função para obter o tempo de criação de um diretório\n",
    "def obter_tempo_criacao(diretorio):\n",
    "    caminho_completo = os.path.join(diretorio_pai, diretorio)\n",
    "    return os.path.getctime(caminho_completo)\n",
    "\n",
    "# Encontrar o último diretório criado\n",
    "ultimo_diretorio = max(diretorios, key=obter_tempo_criacao)\n",
    "\n",
    "# Caminho completo para o último diretório criado\n",
    "path_to_saved_model = diretorio_pai / str(ultimo_diretorio)\n",
    "\n",
    "agent = QAgent.load_from_disk(env, path_to_saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loops import evaluate\n",
    "rewards, steps = evaluate(\n",
    "    agent, env,\n",
    "    n_episodes=1000,\n",
    "    epsilon=0.00\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards, label='Rewards per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Rewards per Episode')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reward_avg = np.array(rewards).mean()\n",
    "reward_std = np.array(rewards).std()\n",
    "print(f'Reward average {reward_avg:.2f}, std {reward_std:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 4))\n",
    "ax.set_title(\"Rewards\")    \n",
    "pd.Series(rewards).plot(kind='hist', bins=100)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertacao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
