{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def sample_dqn_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Sampler for DQN hyperparams.\n",
    "\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 100, 128, 256, 512])\n",
    "    buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(5e4), int(1e5), int(1e6)])\n",
    "    exploration_final_eps = trial.suggest_float(\"exploration_final_eps\", 0, 0.2)\n",
    "    exploration_fraction = trial.suggest_float(\"exploration_fraction\", 0, 0.5)\n",
    "    target_update_interval = trial.suggest_categorical(\"target_update_interval\", [1, 1000, 5000, 10000, 15000, 20000])\n",
    "    learning_starts = trial.suggest_categorical(\"learning_starts\", [0, 1000, 5000, 10000, 20000])\n",
    "\n",
    "    train_freq = trial.suggest_categorical(\"train_freq\", [1, 4, 8, 16, 128, 256, 1000])\n",
    "    subsample_steps = trial.suggest_categorical(\"subsample_steps\", [1, 2, 4, 8])\n",
    "    gradient_steps = max(train_freq // subsample_steps, 1)\n",
    "\n",
    "    net_arch_type = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\", \"medium\"])\n",
    "    net_arch = {\"tiny\": [64], \"small\": [64, 64], \"medium\": [256, 256]}[net_arch_type]\n",
    "\n",
    "    hyperparams = {\n",
    "        \"gamma\": gamma,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"buffer_size\": buffer_size,\n",
    "        \"train_freq\": train_freq,\n",
    "        \"gradient_steps\": gradient_steps,\n",
    "        \"exploration_fraction\": exploration_fraction,\n",
    "        \"exploration_final_eps\": exploration_final_eps,\n",
    "        \"target_update_interval\": target_update_interval,\n",
    "        \"learning_starts\": learning_starts,\n",
    "        \"policy_kwargs\": dict(net_arch=net_arch),\n",
    "    }\n",
    "\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import gymnasium\n",
    "\n",
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gymnasium.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need.\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "ENV_ID = \"CartPole-v1\"\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}\n",
    "N_EVAL_EPISODES = int(1e3)\n",
    "EVAL_FREQ = int(1e2)\n",
    "N_TIMESTEPS = int(1e3)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Sample hyperparameters.\n",
    "    kwargs = sample_dqn_params(trial)\n",
    "    # Create the RL model.\n",
    "    model = DQN(policy='MlpPolicy', env=ENV_ID, **kwargs)\n",
    "    # Create env used for evaluation.\n",
    "    eval_env = Monitor(gymnasium.make(ENV_ID))\n",
    "    # Create the callback that will periodically evaluate and report the performance.\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=EVAL_FREQ, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN.\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory.\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed.\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 19:11:29,221] A new study created in memory with name: no-name-53575a89-9597-49ec-bb68-a5f92a0c5f70\n",
      "[I 2024-03-08 19:11:59,272] Trial 0 finished with value: 9.357 and parameters: {'gamma': 0.9999, 'learning_rate': 0.00677781642597295, 'batch_size': 256, 'buffer_size': 100000, 'exploration_final_eps': 0.18133605293970886, 'exploration_fraction': 0.45938155778571194, 'target_update_interval': 1000, 'learning_starts': 10000, 'train_freq': 4, 'subsample_steps': 2, 'net_arch': 'small'}. Best is trial 0 with value: 9.357.\n",
      "[I 2024-03-08 19:12:35,461] Trial 1 finished with value: 12.836 and parameters: {'gamma': 0.9, 'learning_rate': 0.00015247067585542835, 'batch_size': 100, 'buffer_size': 50000, 'exploration_final_eps': 0.1932131373000979, 'exploration_fraction': 0.07141960799847397, 'target_update_interval': 20000, 'learning_starts': 20000, 'train_freq': 1000, 'subsample_steps': 1, 'net_arch': 'tiny'}. Best is trial 1 with value: 12.836.\n",
      "[I 2024-03-08 19:13:15,633] Trial 2 finished with value: 12.664 and parameters: {'gamma': 0.999, 'learning_rate': 0.0006593753463547255, 'batch_size': 64, 'buffer_size': 1000000, 'exploration_final_eps': 0.10707125001400906, 'exploration_fraction': 0.43235278736718646, 'target_update_interval': 1000, 'learning_starts': 1000, 'train_freq': 128, 'subsample_steps': 8, 'net_arch': 'medium'}. Best is trial 1 with value: 12.836.\n",
      "[I 2024-03-08 19:14:04,325] Trial 3 finished with value: 9.413 and parameters: {'gamma': 0.9, 'learning_rate': 0.006209605640755568, 'batch_size': 64, 'buffer_size': 10000, 'exploration_final_eps': 0.08120624821862757, 'exploration_fraction': 0.32564864352504547, 'target_update_interval': 5000, 'learning_starts': 0, 'train_freq': 256, 'subsample_steps': 8, 'net_arch': 'medium'}. Best is trial 1 with value: 12.836.\n",
      "[I 2024-03-08 19:16:05,973] Trial 4 finished with value: 42.892 and parameters: {'gamma': 0.9999, 'learning_rate': 0.00011217835259471338, 'batch_size': 512, 'buffer_size': 100000, 'exploration_final_eps': 0.10548029723640158, 'exploration_fraction': 0.09662486462730308, 'target_update_interval': 1, 'learning_starts': 0, 'train_freq': 1000, 'subsample_steps': 1, 'net_arch': 'tiny'}. Best is trial 4 with value: 42.892.\n",
      "[I 2024-03-08 19:16:32,246] Trial 5 finished with value: 9.328 and parameters: {'gamma': 0.9, 'learning_rate': 1.1254561021657318e-05, 'batch_size': 16, 'buffer_size': 100000, 'exploration_final_eps': 0.07039953067607665, 'exploration_fraction': 0.0905458485861278, 'target_update_interval': 1, 'learning_starts': 20000, 'train_freq': 8, 'subsample_steps': 2, 'net_arch': 'tiny'}. Best is trial 4 with value: 42.892.\n",
      "[I 2024-03-08 19:17:03,943] Trial 6 finished with value: 9.365 and parameters: {'gamma': 0.995, 'learning_rate': 0.01606247571845465, 'batch_size': 64, 'buffer_size': 1000000, 'exploration_final_eps': 0.12451364015522551, 'exploration_fraction': 0.16410223216789044, 'target_update_interval': 1000, 'learning_starts': 1000, 'train_freq': 16, 'subsample_steps': 4, 'net_arch': 'small'}. Best is trial 4 with value: 42.892.\n",
      "[I 2024-03-08 19:22:27,782] Trial 7 finished with value: 122.157 and parameters: {'gamma': 0.9999, 'learning_rate': 0.00010095877974258623, 'batch_size': 16, 'buffer_size': 1000000, 'exploration_final_eps': 0.1842663942898469, 'exploration_fraction': 0.28841046597674574, 'target_update_interval': 1000, 'learning_starts': 20000, 'train_freq': 16, 'subsample_steps': 8, 'net_arch': 'tiny'}. Best is trial 7 with value: 122.157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  8\n",
      "Best trial:\n",
      "  Value:  122.157\n",
      "  Params: \n",
      "    gamma: 0.9999\n",
      "    learning_rate: 0.00010095877974258623\n",
      "    batch_size: 16\n",
      "    buffer_size: 1000000\n",
      "    exploration_final_eps: 0.1842663942898469\n",
      "    exploration_fraction: 0.28841046597674574\n",
      "    target_update_interval: 1000\n",
      "    learning_starts: 20000\n",
      "    train_freq: 16\n",
      "    subsample_steps: 8\n",
      "    net_arch: tiny\n",
      "  User attrs:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "N_STARTUP_TRIALS = int(1e1)\n",
    "N_EVALUATIONS = int(3e1)\n",
    "N_TRIALS = int(1e1)\n",
    "\n",
    "# Set pytorch num threads to 1 for faster training.\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "# Do not prune before 1/3 of the max budget is used.\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3)\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 0.21263297674406287,\n",
       " 'exploration_final_eps': 0.20437989752519453,\n",
       " 'train_freq': 0.12007779742006812,\n",
       " 'gamma': 0.10538012421820936,\n",
       " 'learning_rate': 0.09017272483090387,\n",
       " 'learning_starts': 0.08332788446280265,\n",
       " 'subsample_steps': 0.06423318695428099,\n",
       " 'exploration_fraction': 0.058822222974243527,\n",
       " 'net_arch': 0.05475177690790495,\n",
       " 'target_update_interval': 0.006209247066744871,\n",
       " 'buffer_size': 1.2160895584220742e-05}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optuna.importance import get_param_importances\n",
    "\n",
    "get_param_importances(study)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertacao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
